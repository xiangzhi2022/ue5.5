# 自研方案：UE5.5 MetaHuman 口型插件（MetaLipSync）

> 本方案用于指导从零自研一款可在 UE 5.5 驱动 MetaHuman 的口型同步（lip‑sync）插件，覆盖目标、功能范围、技术路线、系统架构、算法设计、工程实现、里程碑、风险与验收标准。默认项目代号 **MetaLipSync**。

---

## 1. 项目目标与范围

**目标**：在 Windows/Mac 编辑器与运行时实现“离线高精度 + 近实时低延迟”的口型同步，直接驱动 MetaHuman 面部系统（ARKit 52 曲线 / AnimBP / Control Rig），提供可视化编辑与批处理能力。

**不做**（Out of Scope）：

* 摄像头面捕（已有 Live Link Face）。
* 自定义人脸骨骼/重拓扑；只适配 MetaHuman 标准。
* 依赖云端推理；默认全部离线本地完成（可选 ONNX 后端）。

---

## 2. 使用场景（User Stories）

* **US1（动画师）**：导入一段 WAV，点击“分析”，得到可编辑的音素区间与 ARKit 曲线关键帧，放入 Sequencer 直接驱动 MetaHuman。
* **US2（previz/过场）**：将音频绑定到角色，Play 时自动口型跟随，端到端延迟 ≤ 120ms。
* **US3（技术美术）**：打开“映射表”，将 viseme → ARKit 曲线/权重自定义并保存为 preset；不同角色可做曲线增益标定。
* **US4（工程/管线）**：命令行批量把一堆音频转成 LipSync 资产或 JSON 曲线，接入 CI 与自动化打包。

---

## 3. 功能范围

### 3.1 MVP（里程碑 M0）

* 离线分析：音频 → 音素/viseme → ARKit 曲线关键帧 → `ULipSyncAsset`。
* 近实时：低算力音频特征 → 主要口型曲线（jawOpen、mouthClose、funnel/pucker、MBP等），平滑与迟滞。
* Sequencer 集成：`LipSync Track` 可视化音素与曲线，关键帧可调，吸附到音素边界。
* Blueprint/C++ API：Analyze、Play、EnableRealtime 等。

### 3.2 增强（M1–M2）

* 语言包（`ULipSyncLanguagePack`）：中文/英文/日文等 viseme 集与 G2P 支持。
* 曲线重映射（`UCurveRemapAsset`）：ARKit 52 ↔ 项目自定义曲线。
* 共发音（Coarticulation）与 prosody（音高/能量）辅助表情。
* 资产压缩与增量更新；CLI 扩展（支持 transcript / 导出 JSON / 指定后端与语言包）。

---

## 4. 技术路线

### 4.1 双通道策略

* **离线精确**：

  1. 采样率统一（如 16kHz/mono）；
  2. 强制对齐/音素识别（Rhubarb 或自研 Builtin 后端；可选文本对齐）；
  3. viseme 序列 → ARKit 52 曲线；
  4. 输出 `ULipSyncAsset`，可直接在 Sequencer 播放。
* **近实时**：

  1. Submix Tap / AudioCapture 拿到音频流；
  2. 轻量模型（TCN/CRNN‑style）或规则特征作口型估计；
  3. 语速自适应平滑器（attack/release 自动调节）；
  4. 动态写入 AnimBP/Control Rig 曲线。

### 4.2 自研推理后端（Builtin）

* **输入特征**：80‑mel、25ms 窗、10ms hop，叠加能量/过零率。
* **模型**：小型深度可分离卷积 + TCN/GRU；输出音素/viseme posterior；帧级 argmax + Viterbi 平滑。
* **部署**：ONNX Runtime（Win: DirectML / Mac: CoreML/Metal；回退 CPU），int8 量化，小于 10MB。

### 4.3 映射与混合

* **Viseme → ARKit52**：通过 preset 将每个 viseme 映射到若干曲线（权重 0..1）。
* **共发音**：二元/三元过渡表对相邻 viseme 做缓入缓出与交叠，避免突然跳变。
* **Prosody**：F0/能量映射到二级表情（如 jaw 振幅/微笑/眉），可一键关闭。

---

## 5. 系统架构

### 5.1 模块划分

* **Runtime 模块：`MetaLipSync`**

  * `ULipSyncComponent`：运行时驱动曲线/播放资产。
  * `ULipSyncSubsystem`：模型加载、离线分析、preset/语言包管理。
  * `ULipSyncAsset`：稀疏关键帧与曲线值。
  * `FPhonemeMapper`：viseme→曲线映射与共发音过渡。
  * `FLiveDriver`：将曲线写入 AnimBP/Control Rig。
* **Editor 模块：`MetaLipSyncEditor`**

  * 导入器/面板：音频→LipSyncAsset；曲线可视化与编辑。
  * Sequencer：`LipSync Track`、吸附、选区重算、强度统一缩放。
  * 资产编辑器：`ULipSyncLanguagePack`、`UCurveRemapAsset`、`ULipSyncPreset`。

### 5.2 可插拔后端

* 通过 `IMetaLipSyncBackend`（Modular Features）暴露 `Analyze/InferRealtime`；内置 *Rhubarb* 与 *Builtin(ONNX)* 两实现，可热插拔。

### 5.3 数据流

* **离线**：Audio → Backend.Analyze → Viseme Timeline → Mapper → ARKit Curves → `ULipSyncAsset` → Sequencer 播放。
* **实时**：Audio Tap → Feature → Backend.InferRealtime → Mapper → Curves → AnimBP/Control Rig。

---

## 6. 编辑器与 UX 设计

* 右键音频：`Create LipSync Asset` → 选择语言包/后端/是否携带台本。
* 曲线视图：波形 + 音素条 + 多曲线折线；框选、批量偏移/缩放；热键重算选区。
* Preset/语言包编辑器：直观的 viseme → 曲线权重表，导入/导出 JSON。
* 角色校准：一键采样求每曲线增益/偏移，存入 `UCurveRemapAsset`。

---

## 7. API 概览

* **Blueprint**：`Analyze Audio To LipSync Asset`、`Play LipSync Asset`、`Enable Realtime LipSync`、`Set Backend`、`Set Language Pack`。
* **C++**：`ULipSyncSubsystem::AnalyzeAudio()`、`ULipSyncComponent::PlayFromAsset()`、`SetRealtimeEnabled()`。
* **命令行**：

```
UECmd -MetaLipSyncAnalyze -Input="a.wav" --backend Builtin --language-pack zh-CN \
      --transcript a.txt --preset Default_ARKIT --remap ProjectFace --export-json a.json
```

---

## 8. 性能与质量指标

* **离线对齐误差**：P50 ≤ 35ms，P90 ≤ 70ms（带台本对齐）。
* **实时延迟**：端到端 ≤ 120ms；帧间抖动 ≤ ±20ms。
* **过渡平滑度**：无可见跳变（以二阶导阈值与人工抽检双指标判定）。
* **CPU/内存**：1080p PIE 中 CPU < 2ms（均值），峰值 < 5ms；增量内存 < 200MB（含模型）。
* **资产体积**：Cook 后较逐帧曲线直存下降 ≥ 50%。

---

## 9. 工程实现

### 9.1 插件骨架

* `.uplugin`：`MetaLipSync`（Runtime），`MetaLipSyncEditor`（Editor），`MetaLipSyncBackend_Rhubarb`，`MetaLipSyncBackend_Builtin`。
* `Build.cs`：依赖 `AudioMixer/SignalProcessing/AnimGraphRuntime/Sequencer/MovieScene/LiveLinkInterface/DeveloperSettings`。
* 目录：`Source/`、`Content/Presets`、`Languages`、`Remaps`、`ThirdParty/`、`Tests/Golden`。

### 9.2 模型与第三方

* `ThirdParty/Builtin`：内置自研 ONNX 模型与版本清单；哈希校验与离线包。
* `ThirdParty/Rhubarb`：可执行或静态库；MIT 许可说明与首次启用告知。

### 9.3 指标与回归

* `STAT MetaLipSync`；日志采集误差/延迟/CPU/内存；
* 回归用 10 段 Golden 音频；CI 出可视化报告（误差曲线/CPU/内存）。

---

## 10. 里程碑与排期

> 以 2 人月工程师 + 1 技美 0.5 人月估算（并行度视资源调整）

* **M0（第 1–2 周）**：插件骨架、Rhubarb 集成、离线分析 → 资产、Sequencer 基础、Blueprint API、MVP Demo。
* **M1（第 3–5 周）**：Builtin 实时后端（int8 量化），语速自适应平滑、语言包/曲线重映射编辑器、角色校准、CLI 扩展。
* **M2（第 6–8 周）**：共发音 + prosody、资产压缩、适配两套示例 Face AnimBP、CI 报告完善、示例工程与文档。

**交付节奏**：双周迭代，迭代末提供 Demo 视频、错误清单与下迭代计划。

---

## 11. 风险与对策

* **多语言差异**：以 viseme 层抽象 + 语言包；允许项目自定义并回传改进表。
* **算力不足**：量化小模型 + EP 自适应（DirectML/CoreML/CPU 回退）；帧率动态采样。
* **兼容性**：ARKit 曲线常量集中与 `UCurveRemapAsset`；提供兼容脚本升级。
* **第三方合规**：离线包 + 许可证提示 + 哈希校验；Mac codesign。
* **精度/稳定性**：Golden 集合回归 + 人工抽检；指标门槛写入 CI。

---

## 12. 验收标准（Definition of Done）

* 通过指标门槛（§8）。
* 在示例工程中，导入 3 段中文/英文音频可一键生成 `ULipSyncAsset` 并驱动 MetaHuman；
* 近实时预览延迟与抖动达标；
* Sequencer 具备吸附、选区重算、强度统一缩放；
* CLI 能批处理并导出 JSON；
* 文档与入门教程齐备（安装、示例、常见问题）。

---

## 13. 交付物

* 插件源码（Runtime/Editor/Backend）+ 示例工程。
* 语言包/Preset/曲线重映射样例。
* 自研 Builtin 模型（ONNX）与推理管线；量化脚本与版本清单。
* 回归数据与 CI 配置；使用手册（中/英）。

---

## 14. 预算与资源（可选）

* 人力：UE 工程 2 人月；技美 0.5 人月；QA 0.5 人月。
* 设备：Win + Mac 编辑器各 1 套；测试音频与耳机/声卡。
* 其他：代码签名、CI Runner、磁盘空间（模型/Golden 数据）。

---

## 15. 附录：关键接口草案

```cpp
class IMetaLipSyncBackend : public IModularFeature {
public:
  virtual FName GetBackendName() const = 0;
  v
```
